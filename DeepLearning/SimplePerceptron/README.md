# SimplePerceptron

## Описание

Этот проект демонстрирует простейшую модель нейронной сети с одной линейной функцией активации, обучаемую с использованием алгоритма градиентного спуска. Цель — показать процесс обновления весов на основе ошибки прогноза.

### Основные компоненты

1. **weighted_sum(inputs, weights)** — функция для вычисления взвешенной суммы входных данных и весов.
2. **neural_network(inputs, weights)** — простая модель нейрона, использующая взвешенную сумму в качестве линейной активации.
3. **scalar_multiply(scalar, vector)** — умножение каждого элемента вектора на скаляр.
4. **gradient_descent_example()** — функция, демонстрирующая работу алгоритма градиентного спуска.

### Переменные

- **toes** — список значений количества пальцев, выступающих в качестве одного из входов.
- **wlrec** — данные по отношению выигрышей.
- **nfans** — количество болельщиков.
- **win_or_lose_binary** — бинарные метки истинных значений (1 — выигрыш, 0 — проигрыш).

### Градиентный спуск

Используется для корректировки весов с целью минимизации квадратичной ошибки:

- Начальные веса: `[0.1, 0.2, -0.1]`
- Скорость обучения (alpha): `0.01`
- Обновление весов происходит с использованием формулы:  
  `weights = [w - alpha * dw for w, dw in zip(weights, weight_deltas)]`

### Как запустить

Запустите скрипт с Python 3:

```bash
python gradient_descent_example.py
```

### Пример вывода

```Пример вывода программы:
Градиентный спуск с несколькими итерациями:

Итерация 1
Прогноз: 0.86000, Ошибка: 0.01960, Дельта: -0.14000
Веса: [0.1119, 0.2014, -0.0983]
Изменение весов: [-1.19, -0.091, -0.168]

...
```

### Зависимости

- Python 3

### Примечания

Этот проект создан для образовательных целей, чтобы понять концепцию градиентного спуска и как изменяются веса в простейшей модели нейронной сети.
